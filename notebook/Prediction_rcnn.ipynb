{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c1fce19a11f95416168ced03c2c70fa818b21a5",
    "colab_type": "text",
    "id": "KBeAf8WgaeSk"
   },
   "source": [
    "Using pre-trained COCO weights trained on http://cocodataset.org as in https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "cdb40bf9115f53810c9e13f0a50e53ed9eb6221b"
   },
   "outputs": [],
   "source": [
    "debug = False\n",
    "# debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40c67b3ff0fa04587dec508363308adaa3ceaf34",
    "colab": {},
    "colab_type": "code",
    "id": "4kjcC6QqywWl"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "# from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e5764759e6a0a9b698b44645658f66873edd807",
    "colab": {},
    "colab_type": "code",
    "id": "yP0XLJx_x_6o"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "# Directory to save logs and trained model\n",
    "ROOT_DIR = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7b64e45f587cd87aeb22e5322f519098434ff5de"
   },
   "outputs": [],
   "source": [
    "!git clone https://www.github.com/matterport/Mask_RCNN.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "576df4c47a23d08b1bdb384245e09aa69f88bbd3",
    "colab_type": "text",
    "id": "kdYzLq1zfKL4"
   },
   "source": [
    "### Install Matterport's Mask-RCNN model from github.\n",
    "See the [Matterport's implementation of Mask-RCNN](https://github.com/matterport/Mask_RCNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "3acbbbe055b6a409d3c50ae0f893acf51b5ae7ba",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-KZXyWwhzOVU",
    "outputId": "2576cc17-7484-4311-ad72-3c5643dcb5bb"
   },
   "outputs": [],
   "source": [
    "# Import Mask RCNN\n",
    "sys.path.append(os.path.join(ROOT_DIR, 'Mask_RCNN'))  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50089cc61791871cdf6a5c0037dc4f28b7b7d7cc",
    "colab": {},
    "colab_type": "code",
    "id": "FghMmiMjzOX2"
   },
   "outputs": [],
   "source": [
    "train_dicom_dir = os.path.join(DATA_DIR, 'image_data')\n",
    "test_dicom_dir = 'test_v2_v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f108beef7838be8a64dd512d395c5dc0ad952790"
   },
   "source": [
    "### Download COCO pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3ee0cd0ee0b1defdec97b94bc736587c1f7631f"
   },
   "outputs": [],
   "source": [
    "COCO_WEIGHTS_PATH = \"mask_rcnn_coco.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "032cc5fe4baa051108106675e6ca4f4fdb2846ed",
    "colab_type": "text",
    "id": "gj-tvDvEaDiC"
   },
   "source": [
    "### Some setup functions and classes for Mask-RCNN\n",
    "\n",
    "- dicom_fps is a list of the dicom image path and filenames \n",
    "- image_annotions is a dictionary of the annotations keyed by the filenames\n",
    "- parsing the dataset returns a list of the image filenames and the annotations dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dfcffc4eaa94a41497717851dee9f702d8a2a73b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "_SfzTa-1zOck",
    "outputId": "91ae8935-bccb-4b8e-9a7e-aa690f95fd9b"
   },
   "outputs": [],
   "source": [
    "# The following parameters have been selected to reduce running time for demonstration purposes \n",
    "# These are not optimal \n",
    "\n",
    "class DetectorConfig(Config):    \n",
    "    # Give the configuration a recognizable name  \n",
    "    NAME = 'airbus'\n",
    "    \n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 9\n",
    "    \n",
    "    BACKBONE = 'resnet50'\n",
    "    \n",
    "    NUM_CLASSES = 2  # background and ship classes\n",
    "    \n",
    "    IMAGE_MIN_DIM = 384\n",
    "    IMAGE_MAX_DIM = 384\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64)\n",
    "    TRAIN_ROIS_PER_IMAGE = 64\n",
    "    MAX_GT_INSTANCES = 14\n",
    "    DETECTION_MAX_INSTANCES = 10\n",
    "    DETECTION_MIN_CONFIDENCE = 0.95\n",
    "    DETECTION_NMS_THRESHOLD = 0.0\n",
    "\n",
    "    STEPS_PER_EPOCH = 15 if debug else 150\n",
    "    VALIDATION_STEPS = 10 if debug else 125\n",
    "    \n",
    "    ## balance out losses\n",
    "    LOSS_WEIGHTS = {\n",
    "        \"rpn_class_loss\": 30.0,\n",
    "        \"rpn_bbox_loss\": 0.8,\n",
    "        \"mrcnn_class_loss\": 6.0,\n",
    "        \"mrcnn_bbox_loss\": 1.0,\n",
    "        \"mrcnn_mask_loss\": 1.2\n",
    "    }\n",
    "\n",
    "config = DetectorConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6136132b1f1b311e297d9432772ec4a81230924f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import montage\n",
    "from skimage.morphology import binary_opening, disk, label\n",
    "import gc; gc.enable() # memory is tight\n",
    "\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "\n",
    "def multi_rle_encode(img, **kwargs):\n",
    "    '''\n",
    "    Encode connected regions as separated masks\n",
    "    '''\n",
    "    labels = label(img)\n",
    "    if img.ndim > 2:\n",
    "        return [rle_encode(np.sum(labels==k, axis=2), **kwargs) for k in np.unique(labels[labels>0])]\n",
    "    else:\n",
    "        return [rle_encode(labels==k, **kwargs) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img, min_max_threshold=1e-3, max_mean_threshold=None):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    if np.max(img) < min_max_threshold:\n",
    "        return '' ## no need to encode if it's all zeros\n",
    "    if max_mean_threshold and np.mean(img) > max_mean_threshold:\n",
    "        return '' ## ignore overfilled mask\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.uint8)\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks |= rle_decode(mask)\n",
    "    return all_masks\n",
    "\n",
    "def masks_as_color(in_mask_list):\n",
    "    # Take the individual ship masks and create a color mask array for each ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.float)\n",
    "    scale = lambda x: (len(in_mask_list)+x+1) / (len(in_mask_list)*2) ## scale the heatmap image to shift \n",
    "    for i,mask in enumerate(in_mask_list):\n",
    "        if isinstance(mask, str):\n",
    "            all_masks[:,:] += scale(i) * rle_decode(mask)\n",
    "    return all_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d3e05fa1a38c637fa228acd62b92dd41117a6672"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "exclude_list = ['6384c3e78.jpg','13703f040.jpg', '14715c06d.jpg',  '33e0ff2d5.jpg',\n",
    "                '4d4e09f2a.jpg', '877691df8.jpg', '8b909bb20.jpg', 'a8d99130e.jpg', \n",
    "                'ad55c3143.jpg', 'c8260c541.jpg', 'd6c7f17c7.jpg', 'dc3e7c901.jpg',\n",
    "                'e44dffe88.jpg', 'ef87bad36.jpg', 'f083256d8.jpg'] #corrupted images\n",
    "\n",
    "train_names = [f for f in os.listdir(train_dicom_dir) if f not in exclude_list]\n",
    "test_names = [f for f in os.listdir(test_dicom_dir) if f not in exclude_list]\n",
    "\n",
    "print(len(train_names), len(test_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3050fa77026411ffdc27bed4a9b667ec0467e4ce"
   },
   "outputs": [],
   "source": [
    "# training dataset\n",
    "SEGMENTATION = '/kaggle/input/test-segmentations/test_segmentations.csv'\n",
    "anns = pd.read_csv(SEGMENTATION)\n",
    "anns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "904636402355a305f7b2ccacb8cc55d52151d2e6"
   },
   "outputs": [],
   "source": [
    "train_names = anns[anns.EncodedPixels.notnull()].ImageId.unique().tolist()  ## override with ships\n",
    "\n",
    "test_size = config.VALIDATION_STEPS * config.IMAGES_PER_GPU\n",
    "image_fps_train, image_fps_val = train_test_split(train_names, test_size=test_size, random_state=42)\n",
    "\n",
    "if debug:\n",
    "    image_fps_train = image_fps_train[:100]\n",
    "    image_fps_val = image_fps_val[:100]\n",
    "    test_names = test_names[:100]\n",
    "    \n",
    "print(len(image_fps_train), len(image_fps_val), len(test_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52bd3ffbdde0173a363055482d675da51c2aba99",
    "colab": {},
    "colab_type": "code",
    "id": "8EBVA1M60yAj"
   },
   "outputs": [],
   "source": [
    "class DetectorDataset(utils.Dataset):\n",
    "    \"\"\"Dataset class for training our dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_fps, image_annotations, orig_height, orig_width):\n",
    "        super().__init__(self)\n",
    "        \n",
    "        # Add classes\n",
    "        self.add_class('ship', 1, 'Ship')\n",
    "        \n",
    "        # add images \n",
    "        for i, fp in enumerate(image_fps):\n",
    "            annotations = image_annotations.query('ImageId==\"' + fp + '\"')['EncodedPixels']\n",
    "            self.add_image('ship', image_id=i, path=os.path.join(train_dicom_dir, fp), \n",
    "                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)\n",
    "            \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        fp = info['path']\n",
    "        image = imread(fp)\n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "            image = np.stack((image,) * 3, -1)\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        annotations = info['annotations']\n",
    "#         print(image_id, annotations)\n",
    "        count = len(annotations)\n",
    "        if count == 0:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)\n",
    "            class_ids = np.zeros((1,), dtype=np.int32)\n",
    "        else:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)\n",
    "            class_ids = np.zeros((count,), dtype=np.int32)\n",
    "            for i, a in enumerate(annotations):\n",
    "                mask[:, :, i] = rle_decode(a)\n",
    "                class_ids[i] = 1\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7aebc88f910b232e3b8759421914a007c6ffed94",
    "colab": {},
    "colab_type": "code",
    "id": "Mxz-pNbt5txY"
   },
   "outputs": [],
   "source": [
    "image_fps, image_annotations = train_names, anns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5143c19dc22bc00d318a3b28cb7e13c7fbacc8a",
    "colab_type": "text",
    "id": "9KUvacUbgiEX"
   },
   "source": [
    "### Create and prepare the training dataset using the DetectorDataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86c3333d4dfb8b7d00ce1f401693d0df4e6254e1",
    "colab": {},
    "colab_type": "code",
    "id": "jwMkhotP0yFf"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# prepare the training dataset\n",
    "dataset_train = DetectorDataset(image_fps_train, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
    "dataset_train.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "313347d838fa8321a714858c8073f98c50c5be26",
    "colab": {},
    "colab_type": "code",
    "id": "K1TkWuGP0yHl"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# prepare the validation dataset\n",
    "dataset_val = DetectorDataset(image_fps_val, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "600a8135d4e382f62797d69e9358f5697873c8f9",
    "colab_type": "text",
    "id": "pEXEt8fygWuC"
   },
   "source": [
    "### Display a random image with bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "491b78ec96d28fcdbbf8e2d7f9320a05d64c9249",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "4xwsrf9G1lHR",
    "outputId": "a13386d3-a918-41fe-8824-13625c9d7b08"
   },
   "outputs": [],
   "source": [
    "# Load and display random sample and their bounding boxes\n",
    "\n",
    "class_ids = [0]\n",
    "while class_ids[0] == 0:  ## look for a mask\n",
    "    image_id = random.choice(dataset_val.image_ids)\n",
    "    image_fp = dataset_val.image_reference(image_id)\n",
    "    image = dataset_val.load_image(image_id)\n",
    "    mask, class_ids = dataset_val.load_mask(image_id)\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "masked = np.zeros(image.shape[:2])\n",
    "for i in range(mask.shape[2]):\n",
    "    masked += mask[:, :, i] ## * image[:, :, 0]\n",
    "plt.imshow(masked, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "print(image_fp)\n",
    "print(class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d885804eaed410878acce982c0851cea142f15da"
   },
   "outputs": [],
   "source": [
    "model_path='/kaggle/input/trained-model/mask_rcnn_airbus_0021.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52138636b2ae5bf444bba808518cd8313bde65cd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "TgpT9AzC2Bgz",
    "outputId": "60f5a175-4666-497d-b4e8-0bdab39a92d0"
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(DetectorConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode='inference', \n",
    "                          config=inference_config,\n",
    "                          model_dir=ROOT_DIR)\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e13c61bee23b791c61ecf1256f7512295cd4d9ab",
    "colab": {},
    "colab_type": "code",
    "id": "9mTBig7D2BjU"
   },
   "outputs": [],
   "source": [
    "# set color for class\n",
    "def get_colors_for_class_ids(class_ids):\n",
    "    colors = []\n",
    "    for class_id in class_ids:\n",
    "        if class_id == 1:\n",
    "            colors.append((.941, .204, .204))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f99fbd3f31ff1a2bd66764835c9b646375364598",
    "colab_type": "text",
    "id": "A8EiL2LOiCr_"
   },
   "source": [
    "### Use the validation dataset to check the predicted box compared to the expected value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "186412199e25b98719f71cfe5e8869abcce516c4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1394
    },
    "colab_type": "code",
    "id": "irheTbrW2Bl0",
    "outputId": "56041ad4-173d-45ab-af67-f54e8333511e"
   },
   "outputs": [],
   "source": [
    "# Show few example of ground truth vs. predictions on the validation dataset \n",
    "dataset = dataset_val\n",
    "fig = plt.figure(figsize=(10, 40))\n",
    "\n",
    "for i in range(8):\n",
    "\n",
    "    image_id = random.choice(dataset.image_ids)\n",
    "    \n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config, \n",
    "                               image_id, use_mini_mask=False)\n",
    "    \n",
    "#     print(original_image.shape)\n",
    "    plt.subplot(8, 2, 2*i + 1)\n",
    "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                                dataset.class_names,\n",
    "                                colors=get_colors_for_class_ids(gt_class_id), ax=fig.axes[-1])\n",
    "    \n",
    "    plt.subplot(8, 2, 2*i + 2)\n",
    "    results = model.detect([original_image]) #, verbose=1)\n",
    "    r = results[0]\n",
    "    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                dataset.class_names, r['scores'], \n",
    "                                colors=get_colors_for_class_ids(r['class_ids']), ax=fig.axes[-1])\n",
    "    fig.savefig(\"predicted_box\"+ str(i) +'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "164e18701a830bc6c42a791feea13549de37289b",
    "colab_type": "text",
    "id": "WcV1cL_aiSc4"
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5a124f21c2918ac4cb40ce99c852b86ea223d7e4"
   },
   "outputs": [],
   "source": [
    "# Get filenames of test dataset images\n",
    "test_image_fps = test_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a5b7afbfbcde9afe9ef3d80263ad7f55a85531f0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DETECTION_TEST_PRED = '/kaggle/input/fine-tuning-resnet34-on-ship-detection-new-data/ship_detection.csv'\n",
    "ship_detection = pd.read_csv(DETECTION_TEST_PRED, index_col='id')\n",
    "ship_detection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "087700e45fc65cb50a889be9f8f87ff757548d02"
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.45\n",
    "test_names_nothing = ship_detection.loc[ship_detection['p_ship'] <= THRESHOLD].index.tolist()\n",
    "len(test_names_nothing), len(ship_detection), len(test_names_nothing)/len(ship_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a5c0c6134408ddbf5a34496d7e9d7be5692e9a1",
    "colab": {},
    "colab_type": "code",
    "id": "C6UWVrbM2Bob"
   },
   "outputs": [],
   "source": [
    "# Make predictions on test images, write out sample submission\n",
    "def predict(image_fps, filepath='submission.csv', min_conf=config.DETECTION_MIN_CONFIDENCE):\n",
    "    # assume square image\n",
    "    resize_factor = ORIG_SIZE / config.IMAGE_SHAPE[0]\n",
    "    #resize_factor = ORIG_SIZE\n",
    "    with open(filepath, 'w') as file:\n",
    "        file.write(\"ImageId,EncodedPixels\\n\")\n",
    "\n",
    "        for image_id in tqdm(image_fps):\n",
    "            found = False\n",
    "            \n",
    "            if image_id not in test_names_nothing:\n",
    "                image = imread(os.path.join(test_dicom_dir, image_id))\n",
    "                # If grayscale. Convert to RGB for consistency.\n",
    "                if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "                    image = np.stack((image,) * 3, -1)\n",
    "#                 image, window, scale, padding, crop = utils.resize_image(\n",
    "#                     image,\n",
    "#                     min_dim=config.IMAGE_MIN_DIM,\n",
    "#                     min_scale=config.IMAGE_MIN_SCALE,\n",
    "#                     max_dim=config.IMAGE_MAX_DIM,\n",
    "#                     mode=config.IMAGE_RESIZE_MODE)\n",
    "\n",
    "                results = model.detect([image])\n",
    "                r = results[0]\n",
    "\n",
    "                assert( len(r['rois']) == len(r['class_ids']) == len(r['scores']) )\n",
    "                if len(r['rois']) == 0:\n",
    "                    pass  ## no ship\n",
    "                else:\n",
    "                    num_instances = len(r['rois'])\n",
    "\n",
    "                    for i in range(num_instances):\n",
    "                        if r['scores'][i] > min_conf:\n",
    "#                             print(r['scores'][i], r['rois'][i], r['masks'].shape, np.sum(r['masks'][...,i]))\n",
    "#                             plt.imshow(r['masks'][...,i], cmap=get_cmap('jet'))\n",
    "                            file.write(image_id + \",\" + rle_encode(r['masks'][...,i]) + \"\\n\")\n",
    "                            found = True\n",
    "\n",
    "            if not found:\n",
    "                file.write(image_id + \",\\n\")  ## no ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0406e7f5aaa4867782c4f9c064f90bba386128e7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "C5cBpNka2Bsv",
    "outputId": "a2af9176-d9d6-49f6-f22a-5a1c455d144f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "submission_fp = os.path.join(ROOT_DIR, 'submission.csv')\n",
    "predict(test_image_fps, filepath=submission_fp)\n",
    "print(submission_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3fd8d178fc51ef0bca94fbb3f423160f08a77edc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1599
    },
    "colab_type": "code",
    "id": "_BjPE_Ee9rbA",
    "outputId": "67b5f053-112b-494a-9ab3-d017bfb440c2"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(submission_fp)\n",
    "print(sub.EncodedPixels.isnull().sum(), sub.ImageId.nunique(), sub.EncodedPixels.isnull().sum()/sub.ImageId.nunique())\n",
    "sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea110f197abc2acb1c3435383f7259079dc0eb0e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show a few test image detection example\n",
    "def visualize_test(): \n",
    "    image_id = random.choice(test_names)\n",
    "    \n",
    "    # original image\n",
    "#     print(image_id)\n",
    "    image = imread(os.path.join(test_dicom_dir, image_id))\n",
    "    \n",
    "    # assume square image \n",
    "    resize_factor = 1 ## ORIG_SIZE / config.IMAGE_SHAPE[0]\n",
    "    \n",
    "    # If grayscale. Convert to RGB for consistency.\n",
    "    if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "        image = np.stack((image,) * 3, -1) \n",
    "#     image, window, scale, padding, crop = utils.resize_image(\n",
    "#         image,\n",
    "#         min_dim=config.IMAGE_MIN_DIM,\n",
    "#         min_scale=config.IMAGE_MIN_SCALE,\n",
    "#         max_dim=config.IMAGE_MAX_DIM,\n",
    "#         mode=config.IMAGE_RESIZE_MODE)\n",
    "\n",
    "    results = model.detect([image])\n",
    "    r = results[0]\n",
    "    for bbox in r['rois']: \n",
    "#         print(bbox)\n",
    "        x1 = int(bbox[1] * resize_factor)\n",
    "        y1 = int(bbox[0] * resize_factor)\n",
    "        x2 = int(bbox[3] * resize_factor)\n",
    "        y2 = int(bbox[2]  * resize_factor)\n",
    "        cv2.rectangle(image, (x1,y1), (x2,y2), (77, 255, 9), 3, 1)\n",
    "        width = x2 - x1 \n",
    "        height = y2 - y1 \n",
    "#         print(\"x {} y {} h {} w {}\".format(x1, y1, width, height))\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax1.set_title(f\"{image_id}\")\n",
    "    ax1.imshow(image)\n",
    "#     ax2.set_title(f\"{len(r['rois'])} masks if prob:{ship_detection.loc[image_id][0]:.6f}\")\n",
    "    ax2.set_title(f\"masked {image_id}\")\n",
    "    ax2.imshow(masks_as_color(sub.query(f\"ImageId=='{image_id}'\")['EncodedPixels']))\n",
    "    \n",
    "    fig.savefig('result_' + str(image_id) +'.png')\n",
    "\n",
    "for i in range(8):\n",
    "    visualize_test()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lesson-3-rsna-pneumonia-detection-challenge-kaggle",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
